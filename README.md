# Rice CMOR 438 Data Science and Machine Learning Projects

This repository contains projects created by **Ruchi Tiwari** and **Dori Olson** for the course **CMOR 438: Data Science and Machine Learning** at Rice University. The purpose of this repository is to illustrate key concepts, algorithms, and applications in both **supervised** and **unsupervised learning** using Python.

## Repository Overview

This repository includes Jupyter notebooks demonstrating the implementation, evaluation, and visualization of various machine learning algorithms. All notebooks are fully reproducible. To replicate the results, download the repository and run the cells sequentially.

## Data

All datasets are located in the **`Data`** folder in the repository root. They are publicly available and sourced from **Kaggle**.

1. **Income Dataset (Supervised Learning)**  
   - Used for classification tasks.  
   - Contains demographic and income information.  
   - Used for models such as **K-Nearest Neighbors, Logistic Regression, Decision Trees, Linear Regression, Perceptron, Multilayer Perceptron, Regression Trees, and Ensemble Methods**.

2. **Obesity Dataset (Unsupervised Learning)**  
   - Used for clustering and community detection tasks.  
   - Contains features related to lifestyle, eating habits, and physical measurements.  
   - Used for **Community Detection, DBSCAN, K-Means Clustering, and PCA** analyses.

## Algorithms and Notebooks

### Supervised Learning

These notebooks cover classical supervised learning techniques applied to real-world datasets:

1. **Decision Trees** – Tree-based models for classification and regression.  
2. **Ensemble Methods / Random Forests** – Combining multiple models for improved performance and feature analysis.  
3. **K-Nearest Neighbors (KNN)** – Classification based on proximity in feature space.  
4. **Linear Regression** – Predicting continuous outcomes and understanding feature importance.  
5. **Logistic Regression** – Binary classification and interpretation of feature weights.  
6. **Multilayer Perceptron** – Neural network with hidden layers for non-linear classification.  
7. **Perceptron** – Single-layer perceptron for linear classification.  
8. **Regression Trees** – Decision trees specialized for predicting continuous targets.  

Each supervised learning notebook has an accompanying README explaining the implementation and dataset used.

### Unsupervised Learning

These notebooks cover clustering and dimensionality reduction techniques:

1. **Community Detection** – Graph-based clustering using k-nearest-neighbor graphs and the Louvain algorithm.  
2. **DBSCAN Clustering** – Density-based clustering to identify core clusters and noise points.  
3. **K-Means Clustering** – Partitioning data into k clusters based on feature similarity.  
4. **Principal Component Analysis (PCA)** – Dimensionality reduction and visualization of high-dimensional data.

Each unsupervised learning notebook has an accompanying README describing the methodology, results, and dataset.


## Author Information

- **Ruchi Tiwari**  
- **Dori Olson**

This repository demonstrates hands-on experience with data preprocessing, model implementation, and analysis across a variety of machine learning algorithms.

